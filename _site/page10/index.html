<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        jax: ["input/TeX","output/HTML-CSS"],
        extensions: ["tex2jax.js"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
        },
     "HTML-CSS": {
      styles: {
        ".MathJax .mo, .MathJax .mi": {}
      }
    }
    });
    </script>

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });

    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>

<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <title>
    
      Discrete notes &middot; Blog
    
  </title>


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/theorems.css">

  <!-- Icons -->
  <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">-->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  <link href='http://discrete-notes.github.io/feed.xml' rel='alternate' type='application/atom+xml'>
</head>


  <body>

    <div class="container content">
      <div class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">Discrete notes</a>

          
              &nbsp;&nbsp;&nbsp;<small><a href="/about/">About</a></small>
          
              &nbsp;&nbsp;&nbsp;<small><a href="/archive/">Archive</a></small>
          

        </h3>
      </div>

      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/more-november-2019">
        More November notes
      </a>
    </h1>

    <span class="post-date">18 Nov 2019</span>

    <p>Some more notes for November 2019.</p>

<hr />
<p><img src="assets/nueva-constitucion.jpg" alt="" class="center-image" width="80%" /></p>
<p align="center"><small><i>
</i></small></p>
<hr />

<h2 id="network-creation-game">Network creation game</h2>

<p>Network generation models are mechanisms to create networks. 
In a classic setting the nodes arrive one after the other and are linked 
to nodes already in 
the network following some rules. 
In another setting, called <em>network creation game</em> the nodes are players, 
and they play a game in which they can choose to pay to be linked to 
other nodes. 
The outcome of the game is a network. 
The cost that a player pays is $\alpha$ for every node it decides to be 
linked to, plus 
the sum of the distances from this node to all the other nodes. 
In other words, a node wants to have short distance to every node, but 
cannot add a link to every node, because it would be too expensive.</p>

<p>For this game one can study the usual objects of 
<a href="https://en.wikipedia.org/wiki/Algorithmic_game_theory">algorithmic game theory</a>:
the <a href="https://en.wikipedia.org/wiki/Nash_equilibrium">Nash equilibrium</a> 
and the
<a href="https://en.wikipedia.org/wiki/Price_of_anarchy">price of anarchy</a>.</p>

<p>It is conjectured that the price of anarchy is constant for 
any value $\alpha$, and <a href="https://arxiv.org/abs/1909.09799">this recent preprint</a> 
makes progress on the conjecture.</p>

<h2 id="lempel-ziv-compression-algorithms">Lempel-Ziv compression algorithms</h2>

<p>Lempel-Ziv algorithm is a classic compression algorithm (or more 
precisely a classic family of algorithms, are there are several versions). 
A <a href="https://semidoc.github.io/lagarde-catastrophe">blog post on Semidoc</a> 
describes the algorithm and gives an overview of 
<a href="https://arxiv.org/abs/1707.04312">this paper</a> which studies how the compression
rate can change when the original text is changed by one bit.</p>

<p>Two recent papers on arxiv deal with Lempel-Ziv:</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/pdf/1910.00941.pdf">The first one</a> gives a new analysis of 
the fact that Lempel-Ziv is optimal for some models of random text (hidden 
Markov sources)</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1802.10347">The second one</a> improves the complexity of 
the algorithm decompressing the text.</p>
  </li>
</ul>

<h2 id="multi-armed-bandit">Multi-armed bandit</h2>

<p><em>Multi-armed bandit</em> is an expression that appears here and there in 
TCS conference, and very often in theoretical machine learning. It is a type of 
problem where one has to make decisions one after the other, to 
maximize some pay-off. Basically, at each round, it has the choice 
between several options called the “arms” of the bandit (like the levers 
of different slot-machines).</p>

<p>A basic version is the following framework:</p>

<p>Given: $k$  arms, $T$ rounds.</p>

<p>In each round $t\in[T]$:
1. Algorithm picks arm $a_t$.
2. Algorithm observes reward $r_t\in [0,1]$ for the chosen arm.</p>

<p>Pay-off: the sum of the rewards</p>

<p>The reward for an arm comes from an unknown distribution, but if the 
algorithm chooses an arm repeatedly, it somehow learns this distribution. 
There is already a lot to say on this simple case, and there are a flurry
of papers about this, these days.</p>

<p><a href="https://arxiv.org/pdf/1904.07272.pdf">Here</a> is a recent introduction 
to multi-armed bandit. Also if you are in Rennes, France, on Wednesday
there is a 
<a href="https://perso.crans.org/besson/phd/defense/">PhD defense on this topic</a>.</p>

<h2 id="delaunay-triangulations-have-perfect-matchings">Delaunay triangulations have perfect matchings</h2>

<p><a href="https://en.wikipedia.org/wiki/Delaunay_triangulation">Delaunay triangulations</a> 
are triangulations of point sets in the plane. I recentely learnt that
the graphs that are Delaunay triangulations, always have a perfect 
matching (that is a matching of size $n/2$ if $n$ is even, and $(n-1)/2$
is $n$ is odd).</p>

<p><img src="assets/delaunay.png" alt="" class="center-image" width="100%" /></p>
<p align="center"><small><i>
A point set, its Delaunay triangulation, and the associated graph with a perfect matching.
</i></small></p>

<p>A short proof of this appeared on arxiv recently, 
<a href="https://arxiv.org/pdf/1907.01617.pdf">here</a>. (Actually it is a stronger
result that is proved, about the so-called “toughness” of Delaunay 
triangulations.)</p>

<h2 id="learning-augmented-algorithms">Learning-augmented algorithms</h2>

<p>Learning-augmented algorithms are algorithms that can use informtation
coming from some machine learning source. 
Here is an example.</p>

<p>Binary search takes $O(\log n)$ in the worst-case. 
Now if you have some neural network (NN) telling you that the element you’re 
looking for is around position $i$, how do you modify your search? 
Well you can begin by testing position $i$. Then, if the NN is not perfect, 
this might not be the right value, but maybe it’s close. Say the value 
you’re looking for is larger. Then you can try to find a position 
that has larger value than your element, for example by doing exponential guesses. 
Once you have both upper and lower bound, you can run the usual binary 
search.</p>

<p>If the error (that is, the number of positions between your element
and the prediction of the NN) is $\mu$, then your algorithm runs in 
$O(\log \mu)$. This is good: if the prediction is good then you speed up 
the search, and if it’s bad, then you do not loose much.</p>

<p>In more general terms, one looks for two properties:</p>

<ul>
  <li>consistency: the better the prediction, the better the algorithm</li>
  <li>robustness: if the predition is bad, then the algorithm does not get 
much worse.</li>
</ul>

<p>Note that for real application, one might also be interested in the running 
time of the NN, and a lot of other things.</p>

<p>Some material on this topic:</p>

<ul>
  <li>a <a href="https://www.mit.edu/~andoni/algoS19/scribes/scribe24.pdf">lecture note</a></li>
  <li><a href="http://theory.stanford.edu/~sergei/slides/HALG-slides.pdf">the slides</a> 
of a talk at <a href="http://2019.highlightsofalgorithms.org/">HALG 2019</a></li>
  <li><a href="https://www.mit.edu/~vakilian/ttic-workshop.html">a workshop</a>.</li>
</ul>


  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page11/">Older</a>
  
  
    
      <a class="pagination-item newer" href="/page9/">Newer</a>
    
  
</div>


      



      <div class="footer">
        <p>
          &copy; 2020. All rights reserved.
        </p>
      </div>
    </div>

  </body>
</html>
