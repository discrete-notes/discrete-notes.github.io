<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        jax: ["input/TeX","output/HTML-CSS"],
        extensions: ["tex2jax.js"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
        },
     "HTML-CSS": {
      styles: {
        ".MathJax .mo, .MathJax .mi": {}
      }
    }
    });
    </script>

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });

    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>

<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <title>
    
      Discrete notes &middot; Blog
    
  </title>


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/theorems.css">

  <!-- Icons -->
  <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">-->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  <link href='http://discrete-notes.github.io/feed.xml' rel='alternate' type='application/atom+xml'>
</head>


  <body>

    <div class="container content">
      <div class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">Discrete notes</a>

          
              &nbsp;&nbsp;&nbsp;<small><a href="/about/">About</a></small>
          
              &nbsp;&nbsp;&nbsp;<small><a href="/archive/">Archive</a></small>
          

        </h3>
      </div>

      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/october-batch-forgotten">
        October batch, forgotten notions
      </a>
    </h1>

    <span class="post-date">24 Jan 2019</span>

    <p><img src="assets/arbre-bw.png" alt="" class="center-image" height="400px" /></p>

<p>I saw many talks in October and I plan to blog a bit about those in some 
posts to come. This first post is about some notions a somehow knew but couldn’t 
really define.</p>

<h2 id="epsilon-nets">$\epsilon$-nets</h2>

<p><a href="https://en.wikipedia.org/wiki/%CE%95-net_(computational_geometry)">$\epsilon$-nets</a> 
are often appear in computational geometry. Consider a set of points $X$ in 
a geometric space, and a collection $C$ of subsets of $X$ (for example you have 
a collection of balls, then it defines the collection of subsets of $X$: the 
points contained in each ball). 
Now you are given an $\epsilon\in [0,1]$. 
An $\epsilon$-net $E$ is a subset of $X$, such that for every element $c$ of $C$ 
that is large enough, $c$ contains an element of $X$, and large enough means: 
<script type="math/tex">\frac{|c|}{|X|}\geq \epsilon.</script></p>

<p>As one can imagine this is a useful tool to build approximation algorithm, as 
one may be able to focus on the net, that is hopefully much smaller than $X$.</p>

<p>The concept is related to the 
<a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension">VC dimension</a>.</p>

<p>A nice introduction with a chocolate-consumer example can be found 
<a href="https://www.ti.inf.ethz.ch/ew/lehre/CG12/lecture/Chapter%2015.pdf">here</a>.</p>

<h2 id="ptas-qptas-etc">PTAS, QPTAS etc.</h2>

<p>A small list of the accronyms for approximation schemes (PTAS is fine for me, 
but after that…):</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme">PTAS</a>, 
polynomial-time approximation scheme: for every $\epsilon$, you get 
approximation $(1+\epsilon)$, in polynomial time. That is when you fix 
$\epsilon$ you get a polynomial in $n$. Typically you have time complexity 
$f(\epsilon)\times n^{g(\epsilon)}$, 
where $f$ and $g$ can be arbitrarily bad.</li>
  <li>EPTAS, for efficient-PTAS: here the exponent should not depend on $\epsilon$. 
With the example above, $g$ is a constant, and $f$ can still be arbitrary.</li>
  <li>FPTAS, for fully-PTAS: the algorithm is polynomial in both $n$ and $1/\epsilon$.
Typically, $g$ is a constant, and $f$ a polynomial in $1/\epsilon$.</li>
  <li>QPTAS, quasi-polynomial-time approximation scheme: this is worse than PTAS, 
because you allow that even for a fixed $\epsilon$ the complexity is only
quasi-polynomial, for example some $n^{\log n}$.</li>
  <li>PRAS, EPRAS, FPRAS: the same as PTAS, EPTAS, FPTAS, but randomized (the result 
has to be a correct approximation with high probability).</li>
</ul>

<p>(Both this section and the previous one originate from the talk of 
<a href="https://www.lamsade.dauphine.fr/~bonnet/">Edouard Bonnet</a> for the paper 
<em><a href="http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f568.pdf">EPTAS for Max Clique on Disks and Unit Balls</a></em> 
at FOCS 2018.)</p>

<h2 id="doubling-dimension">Doubling dimension</h2>

<p>A lot of recent papers prove nice results in doubling metrics. The <a href="https://en.wikipedia.org/wiki/Doubling_space">doubling 
dimension</a> 
of a metric space is the smallest positive $k$ such that every ball of 
the space can be covered by $2^k$ balls of half the radius. You can think of 
the plane, and show that you can cover a ball of radius 1, with 7 balls of 
radius 1/2, which gives doubling dimension 3. More generally for the euclidian 
space $R^d$, the doubling dimension is known to be in $O(d)$. Thus bounded 
doubling dimension is a natural generalization of bounded dimension.</p>

<p>(The notion appears for example in <em><a href="http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f814.pdf">$ε$-Coresets for Clustering (with Outliers) 
in Doubling Metrics</a></em> also 
presented at FOCS.)</p>


  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page27/">Older</a>
  
  
    
      <a class="pagination-item newer" href="/page25/">Newer</a>
    
  
</div>


      



      <div class="footer">
        <p>
          &copy; 2020. All rights reserved.
        </p>
      </div>
    </div>

  </body>
</html>
